# -*- coding: utf-8 -*-
"""Lab2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YxP3sx6rsFMUUoQ-uD75NxzTube234ax

# Activity A

## 2D Array
"""

import numpy as np

# create 2-D array of 3x6 with max value of 25
nCols = 6

np.random.seed(105)
arr_2d = np.random.randint(25, size=(3, nCols))
print(f"Original:\n{arr_2d}")

# copy the original array before we update values
arr_2d_copy = np.copy(arr_2d)

# 1. first row, 6th column
arr_2d_copy[0,5] = 15
print(f"1:\n{arr_2d_copy}")


# 2. replace 2nd row with a new random array (1 row, 6 cols)
arr_2d_copy[1] = np.random.randint(5, size=(1, nCols))
print(f"2:\n{arr_2d_copy}")


# 3. update middle two values of the 3rd using slicing notation.
arr_2d_copy[2][2:4] = 1
print(f"3:\n{arr_2d_copy}")

"""The numpy developers consider comparing two arrays that have more than one element ambigious:

- Are they equal if any elements are the same
- Are they equal *only if* all elements the same value

So the `logical_and()` is used to perform an logical AND on each element:

```
arr1[n] && arr2[n]
```

then call `all()` to confirm all elements are `True`.



"""

# 4. as (3) but re-instate original values by copying from the original array
arr_2d_copy[2][2:4] = arr_2d[2][2:4]
print(f"{arr_2d_copy}")
assert np.logical_and(arr_2d_copy[2], arr_2d[2]).all(), "Step 4"

"""## 3D Array

Seed the random generator, create a 3x5x5 array and copy the array.
"""

np.random.seed(9)

arr_3d = np.random.randint(25, size=(3,5,5))
print(f"Original\n{arr_3d}")

arr_3d_copy = np.copy(arr_3d)

"""Manually set values to `66` from top-left to bottom-right"""

arr_3d_copy[0][0][0] = 66
arr_3d_copy[0][1][1] = 66
arr_3d_copy[0][2][2] = 66
arr_3d_copy[0][3][3] = 66
arr_3d_copy[0][4][4] = 66
print(f"1.\n{arr_3d_copy}")

"""Avoid hard coded indices by getting rows and columns from `shape`. This time set the `66` from bottom-left to top-right using a loop.

The loop uses `reversed()`, which could be replaced with:

```
range (nRows-1, -1, -1)
```

but I find `reversed()` more readable.
"""

nRows = arr_3d_copy.shape[1]
nCols = arr_3d_copy.shape[2]

i = 0
for row in reversed(range(0, nRows)):
  arr_3d_copy[0][row][i] = 66
  i += 1

print(f"2.\n{arr_3d_copy}")

"""This time use slicing."""

i = 0
for row in range(0, nRows):
  arr_3d_copy[1][row, i:i+1] = 66
  i += 1

print(f"3.\n{arr_3d_copy}")

"""This time do top-left to bottom-right and bottom-left to top-right in same loop."""

i = 0
for row in range(0, nRows):
  arr_3d_copy[2][row, i:i+1] = 66
  arr_3d_copy[2][nRows-row-1, i:i+1] = 66
  i += 1

print(f"4.\n{arr_3d_copy}")

"""# Activity B
The [dataset](https://archive.ics.uci.edu/dataset/94/spambase) is "Spambase" which classifies emails as spam/not spam based on 57 features.

It is available on the UCI Machine Learning Repository.

## Get Data Set

---
> I originally used `google.colab.files` package to show an upload prompt, then called Panda's `read_csv()`. But I discovered the `ucimlrepo` package to fetch the dataset directly.
---

On Google CoLab the package can be installed with:
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install ucimlrepo

"""## Use The Dataset

---
> There are 4601 rows and 57 features (columns) in this dataset. To avoid ugly  output when printing 10% rows with 57 columns, I have limited the rows to 10,  rather than 10%, and columns to 6.
---

Documentation for the UCI ML package is found [here](https://github.com/uci-ml-repo/ucimlrepo) but the basics are:

- Use `fetch_ucirepo()` to download the dataset
- This returns a `dotdict` which is similar to a `dict` but it provides access to keys as attributes

The important attributes are in the top level `data`:

- `original` : Dataframe consisting of all IDs, features and targets (including the NumPy array)
- `headers` : List of all variable names/headers

## Task A
"""

import pandas as pd
import numpy as np
from ucimlrepo import fetch_ucirepo

# dataset: a dotdict with original, features, targets, originals amongst others
# each of those is a Panda dataframe.
# details: https://github.com/uci-ml-repo/ucimlrepo
dataset = fetch_ucirepo(id=94)

"""## Task B"""

# data frame
dataframe = dataset.data.original

# for 10% rows: nMaxRows = len(dataframe.values) // 10
nMaxRows = 10
nMaxCols = 6

"""Print `word_freq_our` column."""

print(dataframe['word_freq_our'])

"""Print the first `nMaxRows` of the `word_freq_you` column where `word_freq_you >= 3`."""

columnIndex = dataframe.columns.get_loc('word_freq_you')
resultSeries = dataframe.word_freq_you >= 3
print(dataframe[resultSeries].values[0:nMaxRows, columnIndex:columnIndex+1])

"""Sort by `word_freq_you` max value and print the first `nMaxRows` rows."""

dataframe_sorted = dataframe.sort_values(by='word_freq_you', ascending=False)
array_sorted = dataframe_sorted["word_freq_you"].values

print(array_sorted[0:nMaxRows])

"""## Task C

"""

# without this call, scientific notation is used
np.set_printoptions(formatter={'float': '{: 0.3f}'.format},
                    suppress=True)

print(f"Showing {nMaxRows} rows")
print(dataframe.values[0:nMaxRows, 0:nMaxCols])

"""I also discovered the Pandas `option_context()` to set `max_rows` and `max_columns`. But rather printing the first `n` rows, it prints the first few rows and the last few rows. And similar for the columns."""

with pd.option_context('display.max_rows', nMaxRows, 'display.max_columns', nMaxCols):
    print(dataset.data.original)

"""# Activity C

> I've reduced this to a few columns because there are so many.
"""

columnNames = ['capital_run_length_average',
               'capital_run_length_total',
               'capital_run_length_longest']


for col in columnNames:
  repeated = dataframe[col].value_counts().nlargest(5).index.tolist()
  print((f'{col}'
          '\n\tMean: {dataframe[col].mean()}'
          '\n\tStd. Deviation: {dataframe[col].std() }'
          '\n\tFive Most Repeated: {repeated}'))